{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polymatvericks/plant-watering-workshop/blob/main/Black_in_Robotics_Outreach_Computer_Vision_%26_Robotics_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Black in Robotics Outreach: Computer Vision & Robotics\n",
        "\n",
        "### Welcome to Your Computer Vision Journey! ü§ñüëÅÔ∏è\n",
        "\n",
        "**What you will learn in Section 1 (20 minutes):**\n",
        "- Python programming fundamentals\n",
        "- How to use Google Colab and Python for computer vision\n",
        "\n",
        "**What you will learn in Section 2 (25 minutes):**\n",
        "- That images are just data you can manipulate\n",
        "- How to use OpenCV library for image processing\n",
        "- 3 different methods to read Images (url, camera, and colab upload)\n",
        "- Understanding the 3 different Image Channels for RGB images.\n",
        "- Cropping and Annotating Images\n",
        "- Splitting and Merging Images\n",
        "\n",
        "**What you will learn in Section 3 (25 minutes):**\n",
        "- Videos are just picture frames\n",
        "- Basics of Object Detection and the Pipeline\n",
        "- Using Yolo pretrained model for object detection in uploaded images\n",
        "- Using Yolo pretrained model for object detection on live video footage from the webcam\n",
        "\n",
        "---\n",
        "\n",
        "**Important Notes:**\n",
        "- Read each markdown section carefully before running code\n",
        "- Follow the TO-DO lists in each section\n",
        "- Fill in the missing code where you see `# TODO:` comments\n",
        "- Ask for help if you get stuck!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ysraq1uQ8TCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Setting Up Our Digital Lab\n",
        "\n",
        "### Understanding Python Libraries (Modules)\n",
        "\n",
        "Think of Python libraries like apps on your phone. Each library gives Python special abilities:\n",
        "\n",
        "- **OpenCV (`cv2`)**: The computer vision powerhouse - reads, processes, and saves images\n",
        "- **NumPy (`np`)**: Mathematical operations on image data (images are just arrays of numbers!)\n",
        "- **Matplotlib (`plt`)**: Creates beautiful visualizations and displays our images\n",
        "- **Google Colab tools**: Allows us to upload and download files\n",
        "\n",
        "### TO-DO List for This Section:\n",
        "- [ ] Run the import code cell below\n",
        "- [ ] Make sure you see the success messages\n",
        "- [ ] If you get errors, raise your hand for help\n",
        "- [ ] Understand that `import` gives us access to pre-built tools"
      ],
      "metadata": {
        "id": "kJAJZhcaAT8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIBRARY IMPORTS - Your Computer Vision Toolkit\n",
        "\n",
        "import cv2                       # OpenCV for computer vision\n",
        "import numpy as np               # NumPy for numerical operations\n",
        "import matplotlib.pyplot as plt  # Matplotlib for displaying images\n",
        "from google.colab import files   # For uploading files\n",
        "import urllib.request            # For downloading images from URLs\n",
        "import io\n",
        "from PIL import Image\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up matplotlib for proper image display\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üéâ Computer Vision Toolkit Ready!\")\n",
        "print(\"‚úÖ OpenCV imported - for image processing\")\n",
        "print(\"‚úÖ NumPy imported - for numerical operations\")\n",
        "print(\"‚úÖ Matplotlib imported - for visualization\")\n",
        "print(\"‚úÖ Colab tools imported - for file operations\")"
      ],
      "metadata": {
        "id": "_rZhgM2ayuYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "\n",
        "Helper Functions are just there to make life easier for us - just run them and move on ASAP üòâ"
      ],
      "metadata": {
        "id": "uUDF8Rn2_F27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPER FUNCTIONS - Making Image Display Easy\n",
        "\n",
        "def show_image(image, title=\"Image\", figsize=(10, 6), show_coords=False):\n",
        "    \"\"\"\n",
        "    Display an image with proper color conversion and formatting\n",
        "\n",
        "    Parameters:\n",
        "    - image: the image array to display\n",
        "    - title: title for the image\n",
        "    - figsize: size of the display\n",
        "    - show_coords: whether to show coordinate grid\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Check if image is grayscale (2D) or color (3D)\n",
        "    if len(image.shape) == 2:  # Grayscale\n",
        "        plt.imshow(image, cmap='gray')\n",
        "    else:  # Color image\n",
        "        # Convert BGR to RGB for proper display\n",
        "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    plt.title(title, fontsize=16, fontweight='bold')\n",
        "\n",
        "    if show_coords:\n",
        "        plt.xlabel('X (Column) ‚Üí', fontsize=12)\n",
        "        plt.ylabel('Y (Row) ‚Üì', fontsize=12)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_images_grid(images, titles, rows=1, cols=2, figsize=(15, 6)):\n",
        "    \"\"\"\n",
        "    Display multiple images in a grid layout\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "\n",
        "    if rows * cols == 1:\n",
        "        axes = [axes]\n",
        "    elif rows == 1 or cols == 1:\n",
        "        axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        if i < len(axes):\n",
        "            if len(img.shape) == 2:  # Grayscale\n",
        "                axes[i].imshow(img, cmap='gray')\n",
        "            else:  # Color\n",
        "                axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "            axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for i in range(len(images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def print_image_info(image, name=\"Image\"):\n",
        "    \"\"\"Print detailed information about an image\"\"\"\n",
        "    print(f\"üìä {name} Information:\")\n",
        "    print(f\"   Shape: {image.shape}\")\n",
        "    print(f\"   Data type: {image.dtype}\")\n",
        "    if len(image.shape) == 3:\n",
        "        print(f\"   Channels: {image.shape[2]} (Color)\")\n",
        "    else:\n",
        "        print(f\"   Channels: 1 (Grayscale)\")\n",
        "    print(f\"   Size: {image.size} pixels\")\n",
        "    print(f\"   Min value: {image.min()}\")\n",
        "    print(f\"   Max value: {image.max()}\")\n",
        "    print()\n",
        "\n",
        "print(\"üõ†Ô∏è Helper functions ready!\")"
      ],
      "metadata": {
        "id": "jv44IBsd_H-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üêç Breakout 1: Python Fundamentals for Computer Vision (15 minutes)\n",
        "\n",
        "### Welcome to Python Programming!\n",
        "\n",
        "Before we can teach robots to see, we need to master the language they understand: **Python**!\n",
        "\n",
        "**Why Python for Robotics?**\n",
        "- ü§ñ **Easy to learn**: Simple, readable syntax\n",
        "- üî¨ **Powerful libraries**: Tons of pre-built tools for robotics\n",
        "- üåç **Industry standard**: Used by major tech companies\n",
        "- üöÄ **Great for beginners**: Perfect first programming language\n",
        "\n",
        "**What We'll Cover:**\n",
        "1. **Variables & Basic Operations** - Storing and manipulating data\n",
        "2. **Lists & Slicing** - Working with collections of data\n",
        "3. **Functions** - Creating reusable code blocks\n",
        "4. **Importing Packages** - Using pre-built tools\n",
        "5. **NumPy Arrays** - The foundation of image data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zRS8OXW28v9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1Ô∏è‚É£ Variables and Basic Operations\n",
        "\n",
        "**What are Variables?** Think of variables as labeled boxes or containers üéÅ that store information. These information can later be updated or changed.\n",
        "\n",
        "**Python Data Types:**\n",
        "- **Integers**: Whole numbers (42, -7, 0)\n",
        "- **Floats**: Decimal numbers (3.14, -2.5, 0.0)\n",
        "- **Strings**: Text (\"Hello Robot!\", 'Python')\n",
        "- **Booleans**: True or False values\n",
        "\n",
        "**Basic Operations:**\n",
        "- **Math**: +, -, *, /, ** (power), % (remainder)\n",
        "- **Comparison**: ==, !=, <, >, <=, >=\n",
        "- **String**: + (concatenation), * (repetition)\n"
      ],
      "metadata": {
        "id": "QMCpla1G83Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables and Basic Operations Examples\n",
        "\n",
        "# Integer variables\n",
        "robot_age = 5\n",
        "\n",
        "# Float variables\n",
        "battery_voltage = 3.7\n",
        "\n",
        "# String variables\n",
        "robot_name = \"Vision Bot\"\n",
        "\n",
        "# Boolean variables\n",
        "is_robot_active = True"
      ],
      "metadata": {
        "id": "XkRXyX7C8pqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing/Reading Values"
      ],
      "metadata": {
        "id": "JrbPdagJ8-0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing/Reading Values\n",
        "print(\"Accessing just variable values\\n\")\n",
        "print(robot_age)\n",
        "print(robot_name)\n",
        "print(battery_voltage)\n",
        "print(is_robot_active)"
      ],
      "metadata": {
        "id": "vyVK56be9AMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Or Displaying them with texts\n",
        "\n",
        "Using ```print(f\"Some text + {variable_name}\")```"
      ],
      "metadata": {
        "id": "F1RQWCIU9Gro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing/Reading Values\n",
        "print(\"Accessing variable values with texts\\n\")\n",
        "print(f\"Robot Age: {robot_age}\")\n",
        "print(f\"Robot Name: {robot_name}\")\n",
        "print(f\"Battery Voltage: {battery_voltage}\")\n",
        "print(f\"Is Robot Active: {is_robot_active}\")"
      ],
      "metadata": {
        "id": "gUPAxn4J9FLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating the Values of Variables"
      ],
      "metadata": {
        "id": "26hOjlYY9Maw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic math operations\n",
        "\n",
        "# Integers\n",
        "robot_age_updated = 5 + 5\n",
        "age_in_months = robot_age * 12\n",
        "\n",
        "# String operations\n",
        "greeting = \"Hello, I am \" + robot_name"
      ],
      "metadata": {
        "id": "LkRBLGJT9OU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"Updating variable values\\n\")\n",
        "print(f\"Updated Robot Age: {robot_age_updated}\")\n",
        "print(f\"Age in months: {age_in_months}\")\n",
        "print(f\"Greeting: {greeting}\")"
      ],
      "metadata": {
        "id": "zWI0tp_m9QKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 1.1: Your Turn with Variables!\n",
        "\n",
        "**Your Mission:** Create variables about yourself and perform operations with them.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Create variables for your personal information\n",
        "- [ ] Perform mathematical operations\n",
        "- [ ] Use string concatenation\n",
        "- [ ] Display results with print statements\n",
        "- [ ] Experiment with different data types"
      ],
      "metadata": {
        "id": "9sjTNSIo9TBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.1: Create Your Own Variables\n",
        "\n",
        "# TODO: Create variables about yourself\n",
        "your_name =           # Put your name here\n",
        "your_age =             # Put your age here\n",
        "favorite_subject =    # Put your favorite subject here\n",
        "hours_of_sleep =     # Average hours you sleep per night\n",
        "\n",
        "print(\"üëã About Me:\\n\")\n",
        "print(f\"___: {your_name}\")              # TODO: Fill in \"Name\"\n",
        "print(f\"Age: {} years old!)\")           # TODO: Fill in your age variable\n",
        "print(f\"___: {favorite_subject}\")       # TODO: Fill in appropriate label"
      ],
      "metadata": {
        "id": "FFQzDUtZ9U51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Perform mathematical operations on some of the variables above\n",
        "age_in_days = your_age * ___    # Calculate your age in days (hint: how many days are in a year)\n",
        "sleep_per_week = hours_of_sleep * ___  # Hours of sleep per week (hint: how many days in a week)\n",
        "\n",
        "\n",
        "# TODO: Create string combinations using the variables you created earlier or just an integer where neccessary\n",
        "introduction = \"Hi! My name is \" + ___  # Complete the introduction using your name variable\n",
        "subject_love = \"I love \" + ___ + \"!\"     # Express your love for your subject using your favourite subject variable\n",
        "\n",
        "# TODO: Display your results\n",
        "print(f\"Sleep: {hours_of_sleep} hours/night ({sleep_per_week} hours/week)\")\n",
        "print(f\"Introduction: {introduction}\")\n",
        "print(f\"Subject: {subject_love}\")"
      ],
      "metadata": {
        "id": "kdOZAHZQ9Uyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2Ô∏è‚É£ Lists and Slicing\n",
        "\n",
        "**What are Lists?** Collections of items stored in order. Perfect for storing multiple pieces of related data!\n",
        "\n",
        "**List Basics:**\n",
        "- **Creating**: `my_list = [1, 2, 3, 4, 5]`\n",
        "- **Accessing**: `my_list[0]` (first item), `my_list[-1]` (last item)\n",
        "- **Length**: `len(my_list)`\n",
        "- **Adding**: `my_list.append(item)`\n",
        "\n",
        "**Slicing Magic:**\n",
        "- **Basic slice**: `my_list[start:end]`\n",
        "- **From beginning**: `my_list[:3]` (first 3 items)\n",
        "- **To end**: `my_list[2:]` (from index 2 to end)\n",
        "- **Step**: `my_list[::2]` (every 2nd item)\n",
        "\n",
        "**Why Important for Images?** Images are like 2D lists of pixel values!\n",
        "\n",
        "**Lists and Slicing Examples:**"
      ],
      "metadata": {
        "id": "1GVr05qh9Zf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of robot-related data\n",
        "sensor_readings = [23, 45, 67, 89, 12, 34, 56, 78]\n",
        "robot_names = [\"R2D2\", \"WALL-E\", \"Optimus\", \"BB-8\", \"C3PO\"]\n",
        "\n",
        "# Basic list operations\n",
        "print(\"üìä Basic List Information\\n\")\n",
        "print(f\"Sensor readings: {sensor_readings}\")\n",
        "print(f\"Number of sensors: {len(sensor_readings)}\")\n",
        "print(f\"First reading: {sensor_readings[0]}\")\n",
        "print(f\"Last reading: {sensor_readings[-1]}\")\n",
        "print(f\"Robot names: {robot_names}\")"
      ],
      "metadata": {
        "id": "pbdHyxUz9UmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List slicing examples\n",
        "print(\"\\n‚úÇÔ∏è Slicing Examples:\")\n",
        "print(f\"First 3 sensors: {sensor_readings[:3]}\")\n",
        "print(f\"Last 3 sensors: {sensor_readings[-3:]}\")\n",
        "print(f\"Middle readings: {sensor_readings[2:6]}\")\n",
        "print(f\"Reversed list: {sensor_readings[::-1]}\")"
      ],
      "metadata": {
        "id": "l7xEuCT89gt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 1.2: Master Lists and Slicing!\n",
        "\n",
        "**Your Mission:** Work with lists of data and practice slicing techniques.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Create your own lists\n",
        "- [ ] Practice accessing individual items\n",
        "- [ ] Use slicing to get parts of lists\n",
        "- [ ] Perform operations on list data\n",
        "- [ ] Understand how this relates to image processing"
      ],
      "metadata": {
        "id": "4fC7sfai9jT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.2: Practice with Lists and Slicing\n",
        "\n",
        "# TODO: Create your own lists\n",
        "favorite_foods = [\"___\", \"___\", \"___\"]  # Fill with your favorite foods\n",
        "test_scores = [85, 92, 78, 91, 87]  # Pretend test scores\n",
        "pixel_row = [0, 50, 100, 150, 100, 50]  # Simulated pixel values\n",
        "\n",
        "# TODO: Basic list access\n",
        "first_food = favorite_foods[___]     # Get the first food (index?)\n",
        "last_food = favorite_foods[___]      # Get the last food (hint: -1)\n",
        "middle_score = test_scores[___]      # Get the middle score using its index\n",
        "\n",
        "print(\"üçï Food Preferences:\")\n",
        "print(f\"All foods: {favorite_foods}\")\n",
        "print(f\"First favorite: {first_food}\")\n",
        "print(f\"Last favorite: {last_food}\")\n",
        "print(f\"Total favorites: {len(favorite_foods)}\")"
      ],
      "metadata": {
        "id": "bS-DSO549gqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Practice slicing\n",
        "top_3_foods =     # Get first 3 foods\n",
        "last_2_foods =       # Get last 2 foods\n",
        "first_half_pixel_values =  # Get first half of pixel values\n",
        "\n",
        "print(f\"‚úÇÔ∏è Slicing Practice\\n\")\n",
        "print(f\"Top 3 foods: {top_3_foods}\")\n",
        "print(f\"Last 2 foods: {last_2_foods}\")\n",
        "print(f\"First half pixel values: {first_half_pixel_values}\")"
      ],
      "metadata": {
        "id": "uBCQqXx49gku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3Ô∏è‚É£ Functions - Building Reusable Code\n",
        "\n",
        "**What are Functions?** Reusable blocks of code that perform specific tasks. Like having a robot assistant that follows your instructions!\n",
        "\n",
        "**Function Structure:**\n",
        "```python\n",
        "def function_name(parameters):\n",
        "    \"\"\"Description of what the function does\"\"\"\n",
        "    # Code that does the work\n",
        "    return result  # Optional: return a value\n",
        "```\n",
        "\n",
        "**Why Functions Are Amazing:**\n",
        "- üîÑ **Reusability**: Write once, use many times\n",
        "- üßπ **Organization**: Keep code clean and readable\n",
        "- üêõ **Debugging**: Easier to find and fix problems\n",
        "- üë• **Teamwork**: Share code with others\n",
        "\n",
        "**Example Code:**"
      ],
      "metadata": {
        "id": "c9VknT2d9ofc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions Examples - Building Robot Helpers\n",
        "\n",
        "# greeting\n",
        "def greet_robot(robot_name, mission):\n",
        "    \"\"\"Create a personalized greeting for a robot\"\"\"\n",
        "    greeting = f\"Hello {robot_name}! Ready for mission: {mission}?\"\n",
        "    return greeting\n",
        "\n",
        "# addition\n",
        "def sum_numbers(a, b):\n",
        "    \"\"\"Add two numbers together\"\"\"\n",
        "    result = a + b\n",
        "    return result"
      ],
      "metadata": {
        "id": "HnPx4OJT9ggQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our functions\n",
        "print(\"ü§ñ Testing Robot Functions:\")\n",
        "\n",
        "# Test greeting function\n",
        "robot_name = \"Vision Bot\"\n",
        "robot_mission = \"Save the planet\"\n",
        "\n",
        "robot_greeting = greet_robot(robot_name, robot_mission)\n",
        "\n",
        "# or pass in the arguments directly\n",
        "# robot_greating = greet_robot(\"Bir Bot\", \"Save the planet earth\")\n",
        "\n",
        "print(robot_greeting)\n",
        "\n",
        "# Test addition function\n",
        "sum_result = sum_numbers(5, 10)\n",
        "print(f\"Sum: {sum_result}\")"
      ],
      "metadata": {
        "id": "UXB7LHPO9gby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 1.3: Build Your Own Functions!\n",
        "\n",
        "**Your Mission:** Create your own functions for robotics and image processing.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Complete the provided function templates\n",
        "- [ ] Create your own custom function\n",
        "- [ ] Test all functions with different inputs"
      ],
      "metadata": {
        "id": "Me71BX3n9ufW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.3: Build Your Own Robot Functions\n",
        "\n",
        "def subtractionn(a, b):\n",
        "    \"\"\"Subtract the 2nd argument from the first\"\"\"\n",
        "    # TODO: Complete this function\n",
        "\n",
        "    result = ___ - ___\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_first(foodlist):\n",
        "    \"\"\"Get the first element in a list\"\"\"\n",
        "    # TODO: Complete this function\n",
        "    result = ___[___] # Remember to first specify the name of the list variable and then the index of the first element\n",
        "\n",
        "    return result\n",
        "\n",
        "# testing out your functions\n",
        "print(\"ü§ñ Testing Your Functions:\")\n",
        "\n",
        "birth_year =\n",
        "current_year =\n",
        "\n",
        "age = subtractionn(current_year, birth_year)\n",
        "\n",
        "print(f\"Age: {age}\")\n",
        "\n",
        "# testing our the food list\n",
        "\n",
        "# TODO: create a list containing your favoirite food\n",
        "fav_food_list =  # remeber to use square brackets and for the whole list and commas \",\" to seperate individual values\n",
        "\n",
        "first_food = get_first(fav_food_list)\n",
        "print(f\"First food: {first_food}\")\n",
        "\n",
        "print(f\"\\nüéâ Great job creating functions! These are the building blocks of programming!\")"
      ],
      "metadata": {
        "id": "RYZDLD-d9f3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4Ô∏è‚É£ Importing Packages - Using Pre-Built Tools\n",
        "\n",
        "**What are Packages?** Collections of functions and tools that other programmers have created. Instead of reinventing the wheel, we use their work!\n",
        "\n",
        "**Why Import Packages?**\n",
        "- ‚ö° **Speed**: Don't write everything from scratch\n",
        "- üõ°Ô∏è **Reliability**: Well-tested, proven code\n",
        "- üåü **Features**: Advanced capabilities beyond basic Python\n",
        "- ü§ù **Community**: Benefit from thousands of developers' work\n",
        "\n",
        "**Common Import Patterns:**\n",
        "```python\n",
        "import package_name\n",
        "import package_name as nickname\n",
        "from package_name import specific_function\n",
        "from package_name import *  # Import everything (use carefully!)\n",
        "```\n",
        "\n",
        "**NumPy Introduction:**\n",
        "NumPy (Numerical Python) is the foundation of scientific computing in Python. Perfect for handling image data!\n",
        "\n",
        "**Example Code:**"
      ],
      "metadata": {
        "id": "CGhqXIQm91KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Packages and NumPy Introduction\n",
        "\n",
        "# Different ways to import\n",
        "import math                    # Import entire math module\n",
        "import numpy as np            # Import numpy with alias 'np'\n",
        "from random import randint    # Import specific function\n",
        "\n",
        "print(\"üì¶ Package Import Examples\\n\")\n",
        "\n",
        "# Using random function\n",
        "random_number = randint(1, 100)\n",
        "print(f\"Random function: Generated {random_number}\")"
      ],
      "metadata": {
        "id": "7At7L7kn902z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy Exploration"
      ],
      "metadata": {
        "id": "UeTC7OFP96q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create arrays (like lists, but much more powerful)\n",
        "simple_list = [1, 2, 3, 4, 5]\n",
        "numpy_array = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "print(f\"Python list: {simple_list}\")\n",
        "print(f\"NumPy array: {numpy_array}\")\n",
        "print(f\"Array type: {type(numpy_array)}\")\n",
        "\n",
        "# Array operations (much faster than lists for math!)\n",
        "doubled = numpy_array * 2        # Multiply every element by 2\n",
        "squared = numpy_array ** 2       # Square every element\n",
        "added = numpy_array + 10         # Add 10 to every element\n",
        "\n",
        "print(f\"\\nüî¢ Array Operations:\")\n",
        "print(f\"Original: {numpy_array}\")\n",
        "print(f\"Doubled:  {doubled}\")\n",
        "print(f\"Squared:  {squared}\")\n",
        "print(f\"Plus 10:  {added}\")"
      ],
      "metadata": {
        "id": "nIfYSTLl90xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Numpy"
      ],
      "metadata": {
        "id": "dvrKmWab9_Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating special arrays (very useful for images!)\n",
        "zeros = np.zeros(5)           # Array of zeros\n",
        "ones = np.ones(4)             # Array of ones\n",
        "full = np.full(6, 255)        # Array filled with specific value\n",
        "range_array = np.arange(0, 10, 2)  # Array with range of values\n",
        "\n",
        "print(f\"\\nüèóÔ∏è Special Arrays\\n\")\n",
        "print(f\"Zeros: {zeros}\")\n",
        "print(f\"Ones: {ones}\")\n",
        "print(f\"Full (255): {full}\")\n",
        "print(f\"Range: {range_array}\")\n",
        "\n",
        "# 2D arrays - this is how images work!\n",
        "image_like = np.array([[0, 128, 255],\n",
        "                       [64, 192, 100],\n",
        "                       [255, 0, 200]])\n",
        "\n",
        "print(f\"\\nüñºÔ∏è 2D Array (like a tiny image)\\n\")\n",
        "print(image_like)\n",
        "print(f\"Shape: {image_like.shape}\") #  (3 rows, 3 columns)\n",
        "\n",
        "print(f\"\\nThis could represent a 3x3 pixel image!\")"
      ],
      "metadata": {
        "id": "LkFUZKZz90s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5Ô∏è‚É£ NumPy Arrays and Slicing - Image Data Foundation\n",
        "\n",
        "**NumPy Arrays vs Python Lists:**\n",
        "- üöÄ **Speed**: 10-100x faster for mathematical operations\n",
        "- üßÆ **Vectorization**: Apply operations to entire arrays at once\n",
        "- üìê **Multi-dimensional**: Perfect for images (2D) and videos (3D)\n",
        "- üîß **Specialized functions**: Built for scientific computing\n",
        "\n",
        "**Array Slicing:**\n",
        "- **1D**: `array[start:end:step]`\n",
        "- **2D**: `array[row_start:row_end, col_start:col_end]`\n",
        "- **Advanced**: Boolean indexing, fancy indexing\n",
        "\n",
        "**Why This Matters for Images:**\n",
        "Images are just 2D or 3D NumPy arrays of pixel values!\n",
        "\n",
        "**Example Code:**"
      ],
      "metadata": {
        "id": "nsEWUO67-NkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy Arrays and Slicing - The Heart of Image Processing\n",
        "\n",
        "print(\"üî¢ Advanced NumPy for Image Processing:\")\n",
        "\n",
        "# Create a 2D array representing a small grayscale image\n",
        "# Values from 0 (black) to 255 (white)\n",
        "mini_image = np.array([[0,   50,  100, 150, 200],\n",
        "                       [25,  75,  125, 175, 225],\n",
        "                       [50,  100, 150, 200, 255],\n",
        "                       [75,  125, 175, 225, 200],\n",
        "                       [100, 150, 200, 255, 150]])\n",
        "\n",
        "print(f\"Mini image array\\n\")\n",
        "print(mini_image)\n",
        "print(f\"\\nShape: {mini_image.shape} (height, width)\")\n",
        "print(f\"Data type: {mini_image.dtype}\")"
      ],
      "metadata": {
        "id": "EY6PUQVy90n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Array slicing examples\n",
        "\n",
        "# Get specific elements\n",
        "top_left = mini_image[0, 0]           # First row, first column\n",
        "bottom_right = mini_image[-1, -1]     # Last row, last column\n",
        "center = mini_image[2, 2]             # Center pixel\n",
        "\n",
        "print(f\"\\n‚úÇÔ∏è Array Slicing Examples\\n\")\n",
        "print(f\"Top-left pixel: {top_left}\")\n",
        "print(f\"Bottom-right pixel: {bottom_right}\")\n",
        "print(f\"Center pixel: {center}\")"
      ],
      "metadata": {
        "id": "M1XKpA1e90hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rows and columns\n",
        "first_row = mini_image[0, :]          # First row, all columns\n",
        "last_column = mini_image[:, -1]       # All rows, last column\n",
        "\n",
        "print(f\"\\nFirst row: {first_row}\")\n",
        "print(f\"Last column: {last_column}\")\n",
        "\n",
        "# Get sub-regions (like cropping an image!)\n",
        "top_left_quad = mini_image[:2, :2]    # Top-left 2x2 region\n",
        "center_region = mini_image[1:4, 1:4]  # 3x3 center region\n",
        "\n",
        "print(f\"\\nTop-left quadrant:\")\n",
        "print(top_left_quad)\n",
        "print(f\"\\nCenter region:\")\n",
        "print(center_region)"
      ],
      "metadata": {
        "id": "xbnsKVba90d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Array operations (like image filters!)\n",
        "print(f\"\\nüéõÔ∏è Image Operations\\n\")\n",
        "\n",
        "# Brighten the image (add value to all pixels)\n",
        "brightened = mini_image + 60\n",
        "brightened_clip = np.clip(brightened, 0, 255)  # Keep values in valid range\n",
        "\n",
        "# Darken the image (multiply all pixels)\n",
        "darkened = mini_image * 0.7\n",
        "darkened = darkened.astype(np.uint8)  # Convert back to integer\n",
        "\n",
        "print(f\"Original: \\n{mini_image}\\n\")\n",
        "print(f\"Brightened: \\n{brightened}\\n\")\n",
        "print(f\"Brightened clipped: \\n{brightened_clip}\\n\")\n",
        "print(f\"Darkened: \\n{darkened}\")"
      ],
      "metadata": {
        "id": "1TJyADUU90ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 1.4: Master NumPy for Images!\n",
        "\n",
        "**Your Mission:** Work with NumPy arrays like a real computer vision engineer.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Create and manipulate 2D arrays\n",
        "- [ ] Practice array slicing techniques\n",
        "- [ ] Apply mathematical operations to arrays\n",
        "- [ ] Understand how this connects to real image processing\n",
        "- [ ] Experiment with different array operations"
      ],
      "metadata": {
        "id": "50E1T-q8-bcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.4: NumPy Arrays for Image Processing\n",
        "\n",
        "# TODO: Create your own \"image\" array\n",
        "# Create a 6x6 array with values that create an interesting pattern\n",
        "my_image = np.array([[___,  ___, ___, ___],   # Fill in values 0-255\n",
        "                     [___,  ___, ___, ___],   # Try to create a pattern!\n",
        "                     [___,  ___, ___, ___],   # Maybe a gradient or shape?\n",
        "                     [___,  ___, ___, ___]])\n",
        "\n",
        "print(\"üñºÔ∏è Your Image Array\\n\")"
      ],
      "metadata": {
        "id": "t5Ishu78-eS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Print out your image array\n"
      ],
      "metadata": {
        "id": "pFr7mlDY-eOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Print out the shape of the image\n"
      ],
      "metadata": {
        "id": "IovSDGAw-eJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Practice array access\n",
        "\n",
        "top_left_arr = # Top-left corner\n",
        "top_right_arr = # Top-right corner\n",
        "bottom_left_arr = # Bottom-left corner\n",
        "bottom_right_arr = # Bottom-right corner\n",
        "\n",
        "\n",
        "# TODO: Practice slicing\n",
        "# Extract different regions of your image\n",
        "top_half =        # Top half of image\n",
        "left_half =       # Left half of image\n",
        "center_square =   # Center 2x2 square\n",
        "\n",
        "print(f\"\\n‚úÇÔ∏è Image Regions\\n\")\n",
        "print(f\"Top-left array:\\n {top_left}\")\n",
        "print(f\"Top half shape: {top_half.shape}\")\n",
        "print(f\"Left half array:\\n {left_half}\")\n",
        "print(f\"Left half shape: {left_half.shape}\")\n",
        "print(f\"Center square\\n\")\n",
        "print(center_square)"
      ],
      "metadata": {
        "id": "uRUALXv7-eFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Apply image operations\n",
        "# Simulate different image processing effects\n",
        "\n",
        "# Brighten the image\n",
        "brightened = my_image + ___    # Add a value (try 50)\n",
        "brightened = np.clip(brightened, 0, 255)  # Keep in valid range\n",
        "\n",
        "# Create a negative image\n",
        "negative = ___ - my_image      # Subtract from max value (255)\n",
        "\n",
        "print(f\"\\nüé® Image Processing Results\\n\")\n",
        "print(f\"Original image:\\n {my_image}\\n\")\n",
        "print(f\"Brightened image:\\n {brightened}\\n\")\n",
        "print(f\"Negative image:\\n {negative}\\n\")\n",
        "\n",
        "print(f\"\\nüèÜ Congratulations! You're now manipulating images like a computer vision expert!\")\n",
        "print(f\"Every operation you just did is used in real image processing applications!\")"
      ],
      "metadata": {
        "id": "81xPPex--eBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Image Data"
      ],
      "metadata": {
        "id": "Nft1q3DN-sby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample image data\n",
        "sample_image = np.array([[0,   64,  128, 192, 0],\n",
        "                        [32,  96,  160, 224, 200],\n",
        "                        [64,  128, 192, 255, 150],\n",
        "                        [96,  160, 224, 200, 100],\n",
        "                        [128, 192, 255, 150, 50]])\n",
        "\n",
        "# display this array as an image\n",
        "show_image(sample_image, \"Sample Image\", show_coords=True)"
      ],
      "metadata": {
        "id": "SGmMyGYS-d9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Excercise 1.5: Create Your Canvas and Explore Shades!\n",
        "\n",
        "**üß† Your Mission:**  \n",
        "Design different canvas patterns and explore how pixel values translate into visual effects.\n",
        "\n",
        "**‚ú® What You'll Learn:**\n",
        "- How to create arrays that represent image data  \n",
        "- How varying pixel values (0‚Äì255) produce different shades  \n",
        "- How to visualize single-channel (grayscale) images  \n",
        "- The link between numerical values and what we see visually  \n",
        "\n",
        "**‚úÖ TO-DO List:**\n",
        "- [ ] Create basic canvases with various pixel values, like the examples below: ![Canvas Example](https://drive.google.com/uc?export=view&id=1s68essuksR5E8zjBSMqLNeJJjGLd5LI5)\n",
        "- [ ] Experiment with grayscale shades (0 = black, 255 = white)  \n",
        "- [ ] Design patterns by combining different pixel values  \n",
        "- [ ] Discover how computers interpret images as numbers\n",
        "\n"
      ],
      "metadata": {
        "id": "O0WHj4Fy-wHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Activity 1.2: Image Slicing and Value Writing\n",
        "\n",
        "print(\"‚úÇÔ∏è Activity 1.2: Mastering Image Slicing and Value Writing\")\n",
        "\n",
        "# TODO: Create your own image that is similar to the one above\n",
        "my_robot_face = np.array([[_,   _,  _, _, _],\n",
        "                        [_,  _,  _, _, _],\n",
        "                        [_,  _, _, _, _],\n",
        "                        [_,  _, _, _, _],\n",
        "                        [_, _, _, _, _]])\n",
        "\n",
        "# display this array as an image\n",
        "show_image(my_robot_face, \"My Robot Face\", show_coords=True)"
      ],
      "metadata": {
        "id": "C2JJJfRO-d5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Images as Data (Working with actual Images)\n",
        "\n",
        "**üß† Key Concept:** Images are just arrays of numbers!\n",
        "\n",
        "**Grayscale Images:**\n",
        "- 2D array of pixel values\n",
        "- Each pixel: 0 (black) to 255 (white)\n",
        "- Shape: (height, width)\n",
        "\n",
        "**Color Images:**\n",
        "- 3D array with color channels\n",
        "- Each pixel has 3 values: Red, Green, Blue (RGB)\n",
        "- Shape: (height, width, 3)\n",
        "- Each channel: 0 to 255\n",
        "\n",
        "**OpenCV Color Format:**\n",
        "- Uses BGR (Blue, Green, Red) instead of RGB\n",
        "- We need to convert for proper display with matplotlib"
      ],
      "metadata": {
        "id": "pTIANxr-ytxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üñºÔ∏è Breakout 2: Working with Actual Images Computer Vision (15 minutes)"
      ],
      "metadata": {
        "id": "c5ZJyz-GzGnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Part 1: Three Ways to Load Images\n",
        "\n",
        "### Method 1: Upload from Your Computer\n",
        "Upload any image from your device to work with.\n",
        "---"
      ],
      "metadata": {
        "id": "q4eePy8cDDEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# METHOD 1: UPLOAD FROM COMPUTER\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"üìÇ Method 1: Upload Image from Your Computer\")\n",
        "print(\"Click 'Choose Files' and select an image from your device\")\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    # Get the first uploaded file\n",
        "    image_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    uploaded_image = cv2.imread(image_filename)\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        print(f\"‚úÖ Successfully loaded: {image_filename}\")\n",
        "        print_image_info(uploaded_image, \"Uploaded Image\")\n",
        "        show_image(uploaded_image, f\"Uploaded Image: {image_filename}\", show_coords=True)\n",
        "    else:\n",
        "        print(\"‚ùå Error loading image. Please try a different file.\")\n",
        "else:\n",
        "    print(\"No file uploaded. Let's continue with other methods.\")"
      ],
      "metadata": {
        "id": "NybgdXQbzTFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: Download from URL\n",
        "Load images directly from the internet using a web address."
      ],
      "metadata": {
        "id": "G_d7qWxxzflc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 2A: FROM GOOGLE COLAB\n",
        "# Upload the image\n",
        "# get the URL\n",
        "\n",
        "image_url = \"/content/obj_image2.png\"\n",
        "\n",
        "colab_image = cv2.imread(image_url)\n",
        "\n",
        "if colab_image is not None:\n",
        "    print(\"‚úÖ Successfully downloaded and loaded image\")\n",
        "    print_image_info(colab_image, \"Downloaded Image\")\n",
        "    show_image(colab_image, \"Downloaded Image from URL\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Image downloaded but failed to load\")"
      ],
      "metadata": {
        "id": "cYOQ7i2JdI8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 2b: DOWNLOAD FROM URL\n",
        "\n",
        "print(\"üåê Method 2: Download Image from URL\")\n",
        "\n",
        "# Single image URL to download\n",
        "image_url = \"https://drive.google.com/uc?export=download&id=1xLtag2U7vCf_YiNjifMdycd-1ofTBOFq\"\n",
        "\n",
        "\n",
        "# Download and load the image\n",
        "url_image = None\n",
        "\n",
        "print(\"üì• Downloading image from URL...\")\n",
        "urllib.request.urlretrieve(image_url, \"downloaded_image.jpg\")\n",
        "url_image = cv2.imread(\"downloaded_image.jpg\")\n",
        "\n",
        "if url_image is not None:\n",
        "    print(\"‚úÖ Successfully downloaded and loaded image\")\n",
        "    print_image_info(url_image, \"Downloaded Image\")\n",
        "    show_image(url_image, \"Downloaded Image from URL\")\n",
        "else:\n",
        "    print(\"‚ùå Image downloaded but failed to load\")"
      ],
      "metadata": {
        "id": "80dyMoSqzIff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 3: Capture from Webcam\n",
        "Take a live photo using your device's camera."
      ],
      "metadata": {
        "id": "Hq2gNdYt0BNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 3: WEBCAM CAPTURE\n",
        "\n",
        "from IPython.display import HTML, display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import ipywidgets as widgets\n",
        "\n",
        "print(\"üì∑ Method 3: Capture from Webcam\")\n",
        "\n",
        "# Create output areas for camera interface\n",
        "camera_output = widgets.Output()\n",
        "photo_output = widgets.Output()\n",
        "\n",
        "display(widgets.VBox([camera_output, photo_output]))\n",
        "\n",
        "# Webcam capture interface\n",
        "with camera_output:\n",
        "    display(HTML('''\n",
        "    <div style=\"text-align: center; padding: 20px;\">\n",
        "        <h3>üì∑ Webcam Photo Capture</h3>\n",
        "        <div id=\"camera-status\" style=\"margin: 10px 0; color: #666;\">\n",
        "            Click \"Start Camera\" to begin\n",
        "        </div>\n",
        "\n",
        "        <div id=\"video-container\" style=\"display:none; margin: 20px 0;\">\n",
        "            <video id=\"webcam-video\" width=\"400\" height=\"300\" autoplay\n",
        "                   style=\"border: 3px solid #4285F4; border-radius: 10px;\"></video>\n",
        "        </div>\n",
        "\n",
        "        <div style=\"margin: 20px 0;\">\n",
        "            <button id=\"start-camera-btn\" onclick=\"startWebcam()\"\n",
        "                    style=\"padding: 12px 24px; font-size: 16px; background: #4285F4;\n",
        "                           color: white; border: none; border-radius: 6px; cursor: pointer;\">\n",
        "                üé• Start Camera\n",
        "            </button>\n",
        "\n",
        "            <button id=\"capture-photo-btn\" onclick=\"capturePhoto()\"\n",
        "                    style=\"padding: 12px 24px; font-size: 16px; background: #34A853;\n",
        "                           color: white; border: none; border-radius: 6px; margin-left: 10px;\n",
        "                           cursor: pointer; display: none;\">\n",
        "                üì∏ Capture Photo\n",
        "            </button>\n",
        "\n",
        "            <button id=\"retake-btn\" onclick=\"retakePhoto()\"\n",
        "                    style=\"padding: 12px 24px; font-size: 16px; background: #EA4335;\n",
        "                           color: white; border: none; border-radius: 6px; margin-left: 10px;\n",
        "                           cursor: pointer; display: none;\">\n",
        "                üîÑ Retake\n",
        "            </button>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "    let webcamStream = null;\n",
        "    const video = document.getElementById('webcam-video');\n",
        "    const status = document.getElementById('camera-status');\n",
        "    const videoContainer = document.getElementById('video-container');\n",
        "    const startBtn = document.getElementById('start-camera-btn');\n",
        "    const captureBtn = document.getElementById('capture-photo-btn');\n",
        "    const retakeBtn = document.getElementById('retake-btn');\n",
        "\n",
        "    async function startWebcam() {\n",
        "        try {\n",
        "            status.textContent = \"üîÑ Starting camera...\";\n",
        "            webcamStream = await navigator.mediaDevices.getUserMedia({\n",
        "                video: { width: 400, height: 300 }\n",
        "            });\n",
        "\n",
        "            video.srcObject = webcamStream;\n",
        "            videoContainer.style.display = 'block';\n",
        "            startBtn.style.display = 'none';\n",
        "            captureBtn.style.display = 'inline-block';\n",
        "            status.textContent = \"üìπ Camera ready! Click 'Capture Photo' when ready.\";\n",
        "\n",
        "        } catch (error) {\n",
        "            status.textContent = \"‚ùå Camera access denied or not available.\";\n",
        "            console.error('Camera error:', error);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    function capturePhoto() {\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth || 400;\n",
        "        canvas.height = video.videoHeight || 300;\n",
        "\n",
        "        const ctx = canvas.getContext('2d');\n",
        "        ctx.drawImage(video, 0, 0);\n",
        "\n",
        "        const imageData = canvas.toDataURL('image/jpeg', 0.8);\n",
        "\n",
        "        // Stop camera\n",
        "        if (webcamStream) {\n",
        "            webcamStream.getTracks().forEach(track => track.stop());\n",
        "        }\n",
        "\n",
        "        videoContainer.style.display = 'none';\n",
        "        captureBtn.style.display = 'none';\n",
        "        retakeBtn.style.display = 'inline-block';\n",
        "        status.textContent = \"üì∏ Photo captured successfully!\";\n",
        "\n",
        "        // Send to Python\n",
        "        google.colab.kernel.invokeFunction('process_webcam_photo', [imageData], {});\n",
        "    }\n",
        "\n",
        "    function retakePhoto() {\n",
        "        retakeBtn.style.display = 'none';\n",
        "        startBtn.style.display = 'inline-block';\n",
        "        status.textContent = \"Click 'Start Camera' to take another photo.\";\n",
        "    }\n",
        "    </script>\n",
        "    '''))\n",
        "\n",
        "def process_webcam_photo(image_data):\n",
        "    \"\"\"Process the captured webcam photo\"\"\"\n",
        "    try:\n",
        "        # Decode the base64 image\n",
        "        image_bytes = b64decode(image_data.split(',')[1])\n",
        "\n",
        "        # Save the image\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f'webcam_capture_{timestamp}.jpg'\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(image_bytes)\n",
        "\n",
        "        # Convert to OpenCV format\n",
        "        pil_image = Image.open(io.BytesIO(image_bytes))\n",
        "        webcam_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Display the captured photo\n",
        "        with photo_output:\n",
        "            photo_output.clear_output()\n",
        "            print(f\"üì∏ Photo captured at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            print_image_info(webcam_image, \"Webcam Photo\")\n",
        "            show_image(webcam_image, \"Your Webcam Photo\")\n",
        "            print(f\"üíæ Saved as: {filename}\")\n",
        "\n",
        "        return webcam_image\n",
        "\n",
        "    except Exception as e:\n",
        "        with photo_output:\n",
        "            photo_output.clear_output()\n",
        "            print(f\"‚ùå Error processing photo: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Register the callback function\n",
        "try:\n",
        "    from google.colab import output\n",
        "    output.register_callback('process_webcam_photo', process_webcam_photo)\n",
        "except:\n",
        "    print(\"Note: Webcam capture requires Colab environment\")"
      ],
      "metadata": {
        "id": "Gx7gDipSzWfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.1: Choose Your Image and Explore!\n",
        "\n",
        "**Your Mission:** Select one of the three methods above to load an image, then explore its properties.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Successfully load an image using any method\n",
        "- [ ] Examine the image information (shape, size, data type)\n",
        "- [ ] Understand the difference between color and grayscale images\n",
        "- [ ] Experiment with different images\n"
      ],
      "metadata": {
        "id": "TmNEz9kN0aIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.1: Image Loading Practice\n",
        "\n",
        "# TODO: Choose one of the images loaded above and assign it to 'my_image'\n",
        "# You can use: uploaded_image, url_image, or webcam_image (if captured)\n",
        "\n",
        "my_image =  # TODO: Input with your chosen image variable name\n",
        "\n",
        "# TODO: Check if you successfully selected an image\n",
        "if my_image is not None:\n",
        "    print(\"‚úÖ Image selected successfully!\")\n",
        "\n",
        "    # TODO: Display your chosen image with your own title\n",
        "    show_image(my_image, \"\")\n",
        "\n",
        "    # TODO: Print detailed information about your image\n",
        "    print_image_info(my_image, \"My Image\")\n",
        "\n",
        "    # TODO: Answer these questions by examining the output above:\n",
        "    print(\"ü§î Questions to Answer:\")\n",
        "    print(\"1. What is the shape of your image? (height, width, channels)\")\n",
        "    print(\"2. Is your image color or grayscale?\")\n",
        "    print(\"3. What are the minimum and maximum pixel values?\")\n",
        "    print(\"4. How many total pixels does your image contain?\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No image selected. Please choose one from the methods above.\")\n",
        "    print(\"üí° Tip: Make sure to run one of the image loading methods first!\")\n"
      ],
      "metadata": {
        "id": "sUd4_JY40F3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### üåà Part 2: Understanding Color Channels (RGB)\n",
        "\n",
        "### What are Color Channels?\n",
        "\n",
        "Every color image is made up of three separate **channels**:\n",
        "- **Red Channel**: Contains the red intensity for each pixel\n",
        "- **Green Channel**: Contains the green intensity for each pixel  \n",
        "- **Blue Channel**: Contains the blue intensity for each pixel\n",
        "\n",
        "**Key Points:**\n",
        "- Each channel is a grayscale image (0-255 values)\n",
        "- Combining all three channels creates the full color image\n",
        "- OpenCV uses **BGR order** (Blue, Green, Red) instead of RGB\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "2VME5dU60-vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WORKING WITH COLOR CHANNELS\n",
        "\n",
        "# Use the selected image or create a sample if none available\n",
        "work_image = url_image.copy()\n",
        "\n",
        "print(\"üåà Working with Color Channels\")\n",
        "print_image_info(work_image, \"Working Image\")\n",
        "show_image(work_image, \"Working Image\", show_coords=True)"
      ],
      "metadata": {
        "id": "Odnig7751NOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the image into separate channels\n",
        "b_channel, g_channel, r_channel = cv2.split(work_image)\n",
        "\n",
        "print(\"üìä Channel Information:\")\n",
        "print(f\"Blue channel shape: {b_channel.shape}\")\n",
        "print(f\"Green channel shape: {g_channel.shape}\")\n",
        "print(f\"Red channel shape: {r_channel.shape}\")"
      ],
      "metadata": {
        "id": "TvMA8CuS1YiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display individual channels\n",
        "show_images_grid(\n",
        "    [work_image, b_channel, g_channel, r_channel],\n",
        "    [\"Original Image\", \"Blue Channel\", \"Green Channel\", \"Red Channel\"],\n",
        "    rows=1, cols=4, figsize=(18, 5)\n",
        ")"
      ],
      "metadata": {
        "id": "yPQn_UFn1mTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create colored versions of each channel for better visualization\n",
        "merged_channels = cv2.merge([b_channel, g_channel, r_channel])\n",
        "\n",
        "# display the merged channels\n",
        "show_image(merged_channels, \"Merged Channels\", figsize=(10, 6))"
      ],
      "metadata": {
        "id": "oo_v7I-h0gRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.2: Channel Exploration Challenge!\n",
        "\n",
        "**Your Mission:** Experiment with color channels to understand how they work.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Split your image into color channels\n",
        "- [ ] Create custom channel manipulations\n",
        "- [ ] Understand how channels combine to form colors\n",
        "- [ ] Create artistic effects using channel operations"
      ],
      "metadata": {
        "id": "u8KsA27W2pc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 1.2: Channel Manipulation Practice\n",
        "\n",
        "print(\"üéØ Exercise 1.2: Your Turn with Color Channels!\")\n",
        "\n",
        "# TODO: Use your selected image for channel work\n",
        "exercise_image =  # TODO: create a copy of the image you want to use for this exercise\n",
        "\n",
        "show_image(exercise_image, \"Exercise Image\")"
      ],
      "metadata": {
        "id": "UTFuyY-A2viJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Split the image into individual channels\n",
        "b_chan, g_chan, r_chan =   # TODO: Complete this line - which open cv function are we to use\n",
        "\n",
        "print(\"üìä Your Channel Analysis:\")\n",
        "print(f\"Original image shape: {exercise_image.shape}\")\n",
        "print(f\"Blue channel shape: {b_chan.shape}\")"
      ],
      "metadata": {
        "id": "22hU5pQG2yeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Display each channel individually\n",
        "show_images_grid(\n",
        "    [b_chan, g_chan, r_chan],\n",
        "    [\"Your Blue Channel\", \"Your Green Channel\", \"Your Red Channel\"],\n",
        "    rows=1, cols=3\n",
        ")"
      ],
      "metadata": {
        "id": "rG4KkHBK25vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Merge the channels and create custom channel effects\n",
        "merged_channels = cv2.merge([b_chan, g_chan, r_chan])\n",
        "\n",
        "\n",
        "# TODO: display the merged channels\n",
        "show_image(merged_channels, \"Merged Channels\", figsize=(10, 6))\n",
        "\n",
        "# TODO: Answer these questions:\n",
        "print(\"\\nü§î Channel Questions:\")\n",
        "print(\"1. What happens when you reorder the channels (e.g brg or rrb)?\")"
      ],
      "metadata": {
        "id": "YQICi-rc18QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÇÔ∏è Part 3: Image Cropping and Region Selection\n",
        "\n",
        "\n",
        "**Image Coordinate System:**\n",
        "- **Origin (0,0)** is at the **top-left** corner\n",
        "- **X-axis** goes **right** (columns)\n",
        "- **Y-axis** goes **down** (rows)\n",
        "- **Indexing**: `image[y:y+height, x:x+width]`\n",
        "\n",
        "**Cropping Syntax:**\n",
        "```python\n",
        "# Basic crop: image[start_row:end_row, start_col:end_col]\n",
        "cropped = image[100:300, 50:250]  # y=100-300, x=50-250\n",
        "\n",
        "# With channels: image[start_row:end_row, start_col:end_col, :]\n",
        "cropped_color = image[100:300, 50:250, :]\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WccWfDLy3gdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.3: Master Image Cropping!\n",
        "\n",
        "**Your Mission:** Practice precise cropping and region selection by cropping the rgb image to its individual strips\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Understand image coordinate system\n",
        "- [ ] Practice basic cropping operations\n",
        "- [ ] Use the crop function with different parameters\n",
        "- [ ] Create interesting compositions from crops"
      ],
      "metadata": {
        "id": "FYpf9dy54B7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view the details of the rgb image\n",
        "print_image_info(url_image, \"Image for Cropping\")\n",
        "show_image(url_image, \"Original Image for Cropping\", show_coords=True)"
      ],
      "metadata": {
        "id": "Q3eWIVCqNDrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: by looking at the shape and axis, fill in the below\n",
        "\n",
        "# Correct boundaries based on image height = 600 (divide by 3 = 200 pixels per stripe)\n",
        "blue_end =        # TODO: Blue stripe ends at row\n",
        "green_start =     # TODO: Green stripe starts at row\n",
        "green_end =       # TODO: Green stripe ends at row\n",
        "red_start =       # TODO: Red stripe starts at row\n",
        "red_end =         # TODO: Red stripe ends at row\n",
        "\n",
        "# Correct slicing assignments\n",
        "blue_strip = url_image[0:blue_end, :, :]                    # Rows\n",
        "green_strip = url_image[green_start:green_end, :, :]        # Rows\n",
        "red_strip = url_image[red_start:red_end, :, :]              # Rows\n",
        "\n",
        "# Display all strips side by side for comparison\n",
        "show_images_grid(\n",
        "    [blue_strip, green_strip, red_strip],\n",
        "    [\"Blue\", \"Green\", \"Red\"],\n",
        "    rows=1, cols=3, figsize=(18, 6)\n",
        ")"
      ],
      "metadata": {
        "id": "roWc4WJrMinS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Analyze your crops\n",
        "\n",
        "print(f\"\\nüìä Your Crop Analysis\\n\")\n",
        "print(f\"Crop 1 shape: {}\") # TODO: complete to get the shape of the blue strip\n",
        "print(f\"Crop 2 shape: {}\") # TODO: complete to get the shape of the blue strip\n",
        "print(f\"Crop 3 shape: {}\") # TODO: complete to get the shape of the blue strip"
      ],
      "metadata": {
        "id": "wtcWi2CE39ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üé® Part 4: Drawing and Annotation\n",
        "\n",
        "OpenCV provides powerful drawing functions to add:\n",
        "- **Lines and Shapes**: Rectangles, circles, lines\n",
        "- **Text**: Labels and annotations  \n",
        "- **Markers**: Points and crosshairs\n",
        "\n",
        "**Key Drawing Functions:**\n",
        "- `cv2.rectangle(img, pt1, pt2, color, thickness)`: Draw rectangles\n",
        "- `cv2.circle(img, center, radius, color, thickness)`: Draw circles\n",
        "- `cv2.line(img, pt1, pt2, color, thickness)`: Draw lines\n",
        "- `cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType)`: Add text"
      ],
      "metadata": {
        "id": "GU80QjCa4TR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DRAWING AND ANNOTATION\n",
        "\n",
        "print(\"üé® Drawing and Annotation on Images\")\n",
        "\n",
        "# Create a clean canvas for drawing\n",
        "canvas = np.full((400, 600, 3), 255, dtype=np.uint8)\n",
        "\n",
        "# show canvas\n",
        "show_image(canvas, \"Canvas for Drawing\", show_coords=True)"
      ],
      "metadata": {
        "id": "LDAW3TmugNsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drawing parameters\n",
        "color_red = (0, 0, 255)      # BGR format: Red\n",
        "color_green = (0, 255, 0)    # BGR format: Green\n",
        "color_blue = (255, 0, 0)     # BGR format: Blue\n",
        "color_white = (255, 255, 255) # BGR format: White\n",
        "color_black = (0, 0, 0) # BGR format: Black\n",
        "thickness = 3\n",
        "\n",
        "print(\"üñäÔ∏è Drawing Basic Shapes:\")\n",
        "\n",
        "# Draw a rectangle\n",
        "cv2.rectangle(canvas, (50, 50), (150, 120), color_red, thickness)\n",
        "\n",
        "# Draw a circle\n",
        "cv2.circle(canvas, (250, 85), 40, color_green, thickness)\n",
        "\n",
        "# Draw a line\n",
        "cv2.line(canvas, (300, 50), (350, 120), color_blue, thickness)\n",
        "\n",
        "# Add text\n",
        "cv2.putText(canvas, \"Black in Robotics\", (100, 200),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 1, color_black, 2)\n",
        "\n",
        "show_image(canvas, \"Image with Annotations\")"
      ],
      "metadata": {
        "id": "nljqHtrA4GLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.4: Create Your Annotated Masterpiece!\n",
        "\n",
        "**Your Mission:** Practice drawing and annotation to create informative visuals.\n",
        "\n",
        "![Drawing Example](https://drive.google.com/uc?export=view&id=1WyPxkPLgUuuCoix_Oiydghw2PILSbNJl)\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Draw basic shapes on your image\n",
        "- [ ] Add meaningful text labels  \n",
        "- [ ] Create a detection-style annotation\n",
        "- [ ] Experiment with colors and styles"
      ],
      "metadata": {
        "id": "qddd8L1v4pM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CREATIVE DRAWING SPACE\n",
        "# Create a fresh canvas\n",
        "my_canvas = np.zeros((400, 600, 3), dtype=np.uint8) # A Black Canvas\n",
        "\n",
        "# display the canvas\n",
        "show_image(my_canvas, \"My Creative Robot Art Canvas!\", show_coords=1)"
      ],
      "metadata": {
        "id": "7jvoD66LV2r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add your creative drawings here!\n",
        "\n",
        "# Face outline (circle)\n",
        "cv2.circle(__, __, __, __, __)\n",
        "\n",
        "# Eyes (filled circles)\n",
        "cv2.circle(__, __, __, __, __)  # TODO: Yellow left eye\n",
        "cv2.circle(__, __, __, __, __)  # TODO: Yellow right  eye\n",
        "\n",
        "# Mouth (rectangle)\n",
        "cv2.rectangle(__, __, __, __, __)  # TODO:  Red mouth\n",
        "\n",
        "# Add text below the robot\n",
        "cv2.putText(__ , __ , __ ,\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, __, color_white, __ )  # TODO: White subtitle\n",
        "\n",
        "show_image(my_canvas, \"My Creative Robot Art!\", show_coords=True)"
      ],
      "metadata": {
        "id": "NeNcqocx4f6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Break Out 2: Object Detection with YOLO (30 minutes)\n",
        "\n",
        "### Welcome to Intelligent Vision! ü§ñüîç\n",
        "\n",
        "**What is Object Detection?**\n",
        "Object detection is teaching computers to find and identify objects in images, just like humans do naturally!\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Classification**: \"What is this?\" (e.g., \"This is a cat\")\n",
        "- **Localization**: \"Where is it?\" (e.g., \"The cat is at coordinates x,y\")  \n",
        "- **Detection**: Classification + Localization = \"What is it and where?\"\n",
        "\n",
        "**YOLO (You Only Look Once):**\n",
        "- State-of-the-art object detection algorithm\n",
        "- Real-time performance\n",
        "- Detects multiple objects simultaneously\n",
        "- Provides bounding boxes and confidence scores\n",
        "\n",
        "### What You'll Learn:\n",
        "- How object detection works (the pipeline)\n",
        "- Using YOLO for image detection\n",
        "- Processing video frame by frame\n",
        "- Real-time detection with webcam\n",
        "- Understanding detection confidence and classes\n",
        "\n",
        "### TO-DO List for This Section:\n",
        "- [ ] Understand the object detection pipeline\n",
        "- [ ] Install and setup YOLO\n",
        "- [ ] Detect objects in static images\n",
        "- [ ] Process video files frame by frame\n",
        "- [ ] Implement real-time webcam detection\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cfngbSyO5C_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Part 1: Understanding Object Detection Pipeline\n",
        "\n",
        "### The Detection Process:\n",
        "\n",
        "1. **Input**: Image or video frame\n",
        "2. **Preprocessing**: Resize, normalize pixel values\n",
        "3. **Model Inference**: YOLO processes the image\n",
        "4. **Post-processing**: Filter detections, apply thresholds\n",
        "5. **Output**: Bounding boxes, labels, confidence scores"
      ],
      "metadata": {
        "id": "KhiPKIga5GEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP AND INSTALLATION\n",
        "\n",
        "print(\"üîß Setting up Object Detection Environment...\")\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"‚úÖ {package} installed successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"‚ùå Failed to install {package}\")\n",
        "\n",
        "# Install ultralytics (YOLO implementation)\n",
        "print(\"Installing YOLO...\")\n",
        "install_package(\"ultralytics\")\n",
        "\n",
        "# Import necessary libraries\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "    print(\"‚úÖ YOLO imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please restart runtime and try again\")\n",
        "\n",
        "# Import other required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "print(\"üéâ Object Detection setup complete!\")"
      ],
      "metadata": {
        "id": "4oKG7qx_49cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding YOLO Classes\n",
        "\n",
        "YOLO can detect 80 different object classes from the COCO dataset:"
      ],
      "metadata": {
        "id": "5rRoZKqU5Kto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO COCO class names\n",
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',\n",
        "    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',\n",
        "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
        "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
        "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',\n",
        "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
        "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "print(f\"üéØ YOLO can detect {len(COCO_CLASSES)} different object types:\")\n",
        "print(\"Common objects:\", COCO_CLASSES[:20])\n",
        "print(\"Household items:\", COCO_CLASSES[55:75])"
      ],
      "metadata": {
        "id": "eJ9Gd_Aw5JfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### üñºÔ∏è Part 2: Object Detection on Images\n",
        "\n",
        "#### Loading the YOLO Model\n",
        "\n",
        "Let's load a pre-trained YOLO model:"
      ],
      "metadata": {
        "id": "N3WUMLDd5R_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING YOLO MODEL\n",
        "\n",
        "print(\"ü§ñ Loading YOLO Model...\")\n",
        "\n",
        "try:\n",
        "    # Load YOLOv8 nano model (fastest, good for learning)\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    print(\"‚úÖ YOLOv8 Nano model loaded successfully\")\n",
        "    print(f\"üìä Model info: {len(COCO_CLASSES)} classes, optimized for speed\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model loading failed: {e}\")"
      ],
      "metadata": {
        "id": "c6HwAcXj6Wpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detection Function\n",
        "\n",
        "Let's create a function to detect objects and draw results:"
      ],
      "metadata": {
        "id": "qIjDjk0h6YRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_draw(image, model, confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Detect objects in an image and draw bounding boxes\n",
        "\n",
        "    Parameters:\n",
        "    - image: input image (BGR format)\n",
        "    - model: YOLO model\n",
        "    - confidence_threshold: minimum confidence for detection\n",
        "\n",
        "    Returns:\n",
        "    - annotated_image: image with detection boxes\n",
        "    - detections: list of detection information\n",
        "    \"\"\"\n",
        "    # Run YOLO inference\n",
        "    results = model(image, conf=confidence_threshold)\n",
        "\n",
        "    # Get the first result (single image)\n",
        "    result = results[0]\n",
        "\n",
        "    # Create a copy of the image for drawing\n",
        "    annotated_image = image.copy()\n",
        "\n",
        "    # Storage for detection information\n",
        "    detections = []\n",
        "\n",
        "    # Process each detection\n",
        "    if result.boxes is not None:\n",
        "        for box in result.boxes:\n",
        "            # Get bounding box coordinates\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "\n",
        "            # Get confidence and class\n",
        "            confidence = float(box.conf[0].cpu().numpy())\n",
        "            class_id = int(box.cls[0].cpu().numpy())\n",
        "            class_name = COCO_CLASSES[class_id]\n",
        "\n",
        "            # Store detection info\n",
        "            detection_info = {\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'confidence': confidence,\n",
        "                'class': class_name,\n",
        "                'class_id': class_id\n",
        "            }\n",
        "            detections.append(detection_info)\n",
        "\n",
        "            # Choose color based on class\n",
        "            color = (0, 255, 0)  # Green default\n",
        "            if class_name == 'person':\n",
        "                color = (255, 0, 0)  # Blue for person\n",
        "            elif class_name in ['car', 'truck', 'bus']:\n",
        "                color = (0, 0, 255)  # Red for vehicles\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            # Create label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "            # Get text size for background\n",
        "            (text_width, text_height), _ = cv2.getTextSize(\n",
        "                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
        "            )\n",
        "\n",
        "            # Draw label background\n",
        "            cv2.rectangle(annotated_image, (x1, y1 - text_height - 10),\n",
        "                         (x1 + text_width, y1), color, -1)\n",
        "\n",
        "            # Draw label text\n",
        "            cv2.putText(annotated_image, label, (x1, y1 - 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return annotated_image, detections\n",
        "\n",
        "print(\"üîß Detection function created!\")"
      ],
      "metadata": {
        "id": "CHcTZ_375RDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Object Detection on Images\n",
        "\n",
        "Let's test our detection on some images:"
      ],
      "metadata": {
        "id": "sWdga88-5axl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# IMAGE OBJECT DETECTION\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"üéØ Testing Object Detection on Images\")\n",
        "\n",
        "# Download your specific Google Drive image\n",
        "test_images = []\n",
        "\n",
        "print(\"üì• Downloading your Google Drive image...\")\n",
        "try:\n",
        "    # Your Google Drive image URL (converted to direct download)\n",
        "    google_drive_url = \"https://drive.google.com/uc?export=download&id=1tozrXlV4YNs30pjwdjcKYVvPTx_QYM03\"\n",
        "\n",
        "    # Download the image\n",
        "    urllib.request.urlretrieve(google_drive_url, \"your_detection_image.jpg\")\n",
        "    your_image = cv2.imread(\"your_detection_image.jpg\")\n",
        "\n",
        "    if your_image is not None:\n",
        "        print(\"‚úÖ Successfully downloaded your Google Drive image\")\n",
        "        print_image_info(your_image, \"Your Google Drive Image\")\n",
        "        test_images.append(('Your Google Drive Image', your_image))\n",
        "    else:\n",
        "        print(\"‚ùå Image downloaded but failed to load\")\n",
        "        raise Exception(\"Failed to load downloaded image\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to download your image: {e}\")\n",
        "    print(\"üí° Make sure the Google Drive file is set to 'Anyone with the link can view'\")\n",
        "    print(\"üîß Using fallback test image...\")\n",
        "\n",
        "    # Fallback to original test image\n",
        "    try:\n",
        "        test_url = \"https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg\"\n",
        "        urllib.request.urlretrieve(test_url, \"test_detection.jpg\")\n",
        "        test_img = cv2.imread(\"test_detection.jpg\")\n",
        "        if test_img is not None:\n",
        "            test_images.append(('Fallback Test Image', test_img))\n",
        "    except:\n",
        "        print(\"Could not download fallback image, creating synthetic scene...\")\n",
        "        # Create a simple scene for testing\n",
        "        test_img = np.zeros((400, 600, 3), dtype=np.uint8)\n",
        "        test_img[100:300, 200:400] = [100, 150, 200]  # Add some color\n",
        "        test_images.append(('Synthetic Image', test_img))\n",
        "\n",
        "# Run detection on available images\n",
        "for name, image in test_images:\n",
        "    print(f\"\\nüîç Detecting objects in: {name}\")\n",
        "\n",
        "    # Run detection\n",
        "    detected_image, detections = detect_and_draw(image, model, confidence_threshold=0.3)\n",
        "\n",
        "    # Print detection results\n",
        "    print(f\"üìä Detection Results:\")\n",
        "    print(f\"   Found {len(detections)} objects\")\n",
        "\n",
        "    for i, detection in enumerate(detections):\n",
        "        bbox = detection['bbox']\n",
        "        print(f\"   {i+1}. {detection['class']}: {detection['confidence']:.3f} at ({bbox[0]}, {bbox[1]}) to ({bbox[2]}, {bbox[3]})\")\n",
        "\n",
        "    # Display results\n",
        "    show_images_grid(\n",
        "        [image, detected_image],\n",
        "        [f\"Original {name}\", f\"Detected Objects ({len(detections)} found)\"],\n",
        "        rows=1, cols=2, figsize=(16, 6)\n",
        "    )"
      ],
      "metadata": {
        "id": "5yv6l6KK5dDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.1: Your Object Detection Challenge!\n",
        "\n",
        "**Your Mission:** Practice object detection and understand the results.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Upload your own image for detection\n",
        "- [ ] Experiment with confidence thresholds\n",
        "- [ ] Analyze detection results\n",
        "- [ ] Understand false positives and false negatives"
      ],
      "metadata": {
        "id": "3NQRcbcf5gk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Exercise 2.1: Object Detection Practice\n",
        "\n",
        "print(\"üéØ Exercise 2.1: Your Object Detection Workshop!\")\n",
        "\n",
        "# TODO: Upload an image for detection\n",
        "print(\"üìÇ Upload an image with objects to detect:\")\n",
        "uploaded_detection = files.upload()\n",
        "\n",
        "if uploaded_detection:\n",
        "    detection_filename = list(uploaded_detection.keys())[0]\n",
        "    your_detection_image = cv2.imread(detection_filename)\n",
        "\n",
        "    if your_detection_image is not None:\n",
        "        print(f\"‚úÖ Loaded: {detection_filename}\")\n",
        "        show_image(your_detection_image, \"Your Image for Detection\")\n",
        "\n",
        "        # TODO: Set your confidence threshold\n",
        "        confidence_threshold = 0.9  # TODO: Experiment with this value (try 0.3, 0.5, 0.7, 0.9)\n",
        "\n",
        "        print(f\"\\nüéöÔ∏è Running Detection with Confidence Threshold: {confidence_threshold}\")\n",
        "\n",
        "        # Run detection with your chosen threshold\n",
        "        detected_img, detections = detect_and_draw(\n",
        "            your_detection_image, model, confidence_threshold=confidence_threshold\n",
        "        )\n",
        "\n",
        "        # Print detection results\n",
        "        print(f\"\\nüìä Detection Results:\")\n",
        "        print(f\"   Objects found: {len(detections)}\")\n",
        "\n",
        "        if len(detections) > 0:\n",
        "            print(f\"   Detected objects:\")\n",
        "            for i, detection in enumerate(detections):\n",
        "                print(f\"   {i+1}. {detection['class']}: {detection['confidence']:.3f}\")\n",
        "        else:\n",
        "            print(f\"   No objects detected at confidence threshold {confidence_threshold}\")\n",
        "            print(f\"   üí° Try lowering the threshold (e.g., 0.3 or 0.5) to see more objects\")\n",
        "\n",
        "        # Display original vs detected\n",
        "        show_images_grid(\n",
        "            [your_detection_image, detected_img],\n",
        "            [\"Original Image\", f\"Detected Objects (Conf: {confidence_threshold})\"],\n",
        "            rows=1, cols=2, figsize=(16, 6)\n",
        "        )\n",
        "\n",
        "        # TODO: Analyze your results\n",
        "        print(f\"\\nü§î Analysis Questions:\")\n",
        "        print(f\"1. How many objects were detected at confidence {confidence_threshold}?\")\n",
        "        print(f\"2. Are the detections accurate? Any false positives or missed objects?\")\n",
        "        print(f\"3. Would you increase or decrease the threshold for better results?\")\n",
        "        print(f\"4. What happens if you change the threshold to 0.3 or 0.5?\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Could not load the uploaded image\")\n",
        "else:\n",
        "    print(\"No image uploaded, using previous examples for analysis\")"
      ],
      "metadata": {
        "id": "Kje57nx95iPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üé¨ Part 3: Video Processing and Frame-by-Frame Detection\n",
        "\n",
        "### Understanding Video as Image Sequences\n",
        "\n",
        "**Key Concept:** Videos are just sequences of images (frames) displayed rapidly!\n",
        "\n",
        "**Video Processing Pipeline:**\n",
        "1. **Read Video**: Load video file or camera stream\n",
        "2. **Extract Frames**: Get individual images from video\n",
        "3. **Process Each Frame**: Apply detection to each image\n",
        "4. **Combine Results**: Create output video or display real-time\n",
        "\n",
        "**Frame Rate Considerations:**\n",
        "- Standard video: 24-30 FPS (Frames Per Second)\n",
        "- Real-time processing: Must process faster than frame rate\n",
        "- Trade-offs: Speed vs accuracy"
      ],
      "metadata": {
        "id": "3rMKA9r75tlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIDEO PROCESSING SETUP\n",
        "\n",
        "print(\"üé¨ Video Processing and Object Detection\")\n",
        "\n",
        "def process_video_file(video_path, model, output_path=None, conf_threshold=0.5, max_frames=None):\n",
        "    \"\"\"\n",
        "    Process a video file and detect objects in each frame\n",
        "\n",
        "    Parameters:\n",
        "    - video_path: path to input video\n",
        "    - model: YOLO model\n",
        "    - output_path: path for output video (optional)\n",
        "    - conf_threshold: confidence threshold for detection\n",
        "    - max_frames: maximum frames to process (for testing)\n",
        "\n",
        "    Returns:\n",
        "    - processed_frames: list of processed frames\n",
        "    - detection_stats: statistics about detections\n",
        "    \"\"\"\n",
        "    # Open video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ùå Error: Could not open video {video_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # Get video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"üìπ Video Info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
        "\n",
        "    # Setup video writer if output path provided\n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    processed_frames = []\n",
        "    detection_stats = {'total_detections': 0, 'frames_processed': 0, 'objects_per_frame': []}\n",
        "\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Process frame\n",
        "        detected_frame, detections = detect_and_draw(frame, model, conf_threshold)\n",
        "\n",
        "        # Update statistics\n",
        "        detection_stats['frames_processed'] += 1\n",
        "        detection_stats['total_detections'] += len(detections)\n",
        "        detection_stats['objects_per_frame'].append(len(detections))\n",
        "\n",
        "        # Save processed frame\n",
        "        processed_frames.append(detected_frame)\n",
        "\n",
        "        # Write to output video if specified\n",
        "        if output_path:\n",
        "            out.write(detected_frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # Break if max_frames reached\n",
        "        if max_frames and frame_count >= max_frames:\n",
        "            break\n",
        "\n",
        "        # Print progress\n",
        "        if frame_count % 30 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            fps_processed = frame_count / elapsed\n",
        "            print(f\"   Processed {frame_count} frames, {fps_processed:.1f} FPS\")\n",
        "\n",
        "    # Clean up\n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "\n",
        "    # Calculate final statistics\n",
        "    avg_objects = np.mean(detection_stats['objects_per_frame']) if detection_stats['objects_per_frame'] else 0\n",
        "    processing_time = time.time() - start_time\n",
        "    avg_fps = frame_count / processing_time\n",
        "\n",
        "    print(f\"‚úÖ Video processing complete!\")\n",
        "    print(f\"   Processed {frame_count} frames in {processing_time:.1f}s\")\n",
        "    print(f\"   Average processing speed: {avg_fps:.1f} FPS\")\n",
        "    print(f\"   Average objects per frame: {avg_objects:.1f}\")\n",
        "\n",
        "    return processed_frames, detection_stats"
      ],
      "metadata": {
        "id": "7TsdCrvji2GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST YOUR UPLOADED VIDEO\n",
        "\n",
        "print(\"üé¨ Testing Your Uploaded Video\")\n",
        "\n",
        "# TODO: Specify the path to your uploaded video file\n",
        "video_path = \"/content/Realistic_Object_Detection_Video_Generation.mp4\"  # TODO: Replace with your actual video filename\n",
        "\n",
        "# Process your video if file exists\n",
        "if os.path.exists(video_path):\n",
        "    print(f\"\\nüîç Processing video: {video_path}\")\n",
        "\n",
        "    # TODO: Adjust these parameters for your video\n",
        "    conf_threshold = 0.5    # TODO: Try different confidence values (0.3, 0.5, 0.7)\n",
        "    max_frames = 120        # TODO: Limit frames for faster testing (or set to None for full video)\n",
        "    output_path = \"/content/detected_video_output.mp4\"  # TODO: Set output path or None\n",
        "\n",
        "    print(f\"‚öôÔ∏è Processing Settings:\")\n",
        "    print(f\"   Confidence threshold: {conf_threshold}\")\n",
        "    print(f\"   Max frames to process: {max_frames if max_frames else 'All frames'}\")\n",
        "    print(f\"   Output video: {output_path if output_path else 'No output video'}\")\n",
        "\n",
        "    # Process the video\n",
        "    processed_frames, stats = process_video_file(\n",
        "        video_path=video_path,\n",
        "        model=model,\n",
        "        output_path=output_path,\n",
        "        conf_threshold=conf_threshold,\n",
        "        max_frames=max_frames\n",
        "    )\n",
        "\n",
        "    if processed_frames and stats:\n",
        "        print(f\"\\nüìä Your Video Analysis Results:\")\n",
        "        print(f\"   Total frames processed: {stats['frames_processed']}\")\n",
        "        print(f\"   Total objects detected: {stats['total_detections']}\")\n",
        "        print(f\"   Average objects per frame: {np.mean(stats['objects_per_frame']):.1f}\")\n",
        "        print(f\"   Max objects in a frame: {max(stats['objects_per_frame']) if stats['objects_per_frame'] else 0}\")\n",
        "        print(f\"   Min objects in a frame: {min(stats['objects_per_frame']) if stats['objects_per_frame'] else 0}\")\n",
        "\n",
        "        # Show sample frames from your video\n",
        "        if len(processed_frames) >= 4:\n",
        "            sample_indices = [0, len(processed_frames)//3, 2*len(processed_frames)//3, len(processed_frames)-1]\n",
        "            sample_frames = [processed_frames[i] for i in sample_indices]\n",
        "            sample_titles = [f\"Frame {i+1}\" for i in sample_indices]\n",
        "\n",
        "            print(f\"\\nüñºÔ∏è Sample Frames from Your Video:\")\n",
        "            show_images_grid(sample_frames, sample_titles, rows=2, cols=2, figsize=(16, 12))\n",
        "\n",
        "        # Download processed video if created\n",
        "        if output_path and os.path.exists(output_path):\n",
        "            print(f\"\\nüíæ Processed video saved as: {output_path}\")\n",
        "            try:\n",
        "                files.download(output_path)\n",
        "                print(\"üì• Download started for processed video\")\n",
        "            except:\n",
        "                print(\"‚ùå Download failed, but file is saved in /content/\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Video processing failed\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Video file not found: {video_path}\")\n",
        "    print(\"üí° Make sure you've uploaded a video file to /content/\")"
      ],
      "metadata": {
        "id": "5E2l_fsp5q1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video Processing Example\n",
        "\n",
        "Let's download and process a sample video:"
      ],
      "metadata": {
        "id": "LoLNZYeF7Cf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Exercise 2.3: Video Object Detection Master!\n",
        "\n",
        "**Your Mission:** Record your own test video and analyze object detection performance over time.\n",
        "\n",
        "**TO-DO List:**\n",
        "- [ ] Record a 30-second video with various objects\n",
        "- [ ] Upload your video to Google Colab\n",
        "- [ ] Process your video with object detection\n",
        "- [ ] Analyze detection patterns and performance\n",
        "\n",
        "## üìπ Step 1: Record Your Test Video\n",
        "\n",
        "**Recording Instructions:**\n",
        "1. **Use your laptop/phone** to record a 30-second video\n",
        "2. **Include diverse objects** from the COCO classes:\n",
        "   - **People**: Yourself, friends, family members\n",
        "   - **Vehicles**: Cars, bicycles, motorcycles (from window/outside)\n",
        "   - **Animals**: Pets (cats, dogs, birds)\n",
        "   - **Household items**: Chairs, laptops, cups, bottles, books\n",
        "   - **Food**: Bananas, apples, pizza, sandwiches\n",
        "\n",
        "**Video Tips:**\n",
        "- **Good lighting**: Record in well-lit areas\n",
        "- **Stable camera**: Keep camera relatively steady\n",
        "- **Multiple objects**: Show 2-5 objects at once when possible\n",
        "- **Movement**: Include some object movement/camera panning\n",
        "- **Various distances**: Show objects up close and far away\n",
        "\n",
        "**File Format:** Save as `.mp4`, `.avi`, or `.mov` (max 50MB for Colab)"
      ],
      "metadata": {
        "id": "aD6IHXoc8CBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üéØ Exercise 3.1: Video Object Detection Analysis!\")\n",
        "\n",
        "# TODO: Upload your recorded video\n",
        "print(\"üì§ Upload your 30-second test video:\")\n",
        "uploaded_video = files.upload()\n",
        "\n",
        "if uploaded_video:\n",
        "    video_filename = list(uploaded_video.keys())[0]\n",
        "    video_path = f\"/content/{video_filename}\"\n",
        "\n",
        "    print(f\"‚úÖ Uploaded: {video_filename}\")\n",
        "\n",
        "    # TODO: Set your processing parameters\n",
        "    conf_threshold = 0.5    # TODO: Try different values (0.3, 0.5, 0.7)\n",
        "    max_frames = 150        # TODO: Process ~5 seconds worth (30fps * 5 = 150)\n",
        "    output_path = \"/content/my_detected_video.mp4\"\n",
        "\n",
        "    print(f\"\\nüé¨ Processing your video...\")\n",
        "    print(f\"   Confidence threshold: {conf_threshold}\")\n",
        "    print(f\"   Processing first {max_frames} frames\")\n",
        "\n",
        "    # Process your video\n",
        "    processed_frames, stats = process_video_file(\n",
        "        video_path=video_path,\n",
        "        model=model,\n",
        "        output_path=output_path,\n",
        "        conf_threshold=conf_threshold,\n",
        "        max_frames=max_frames\n",
        "    )\n",
        "\n",
        "    if processed_frames and stats:\n",
        "        # TODO: Analyze your video results\n",
        "        objects_per_frame = stats['objects_per_frame']\n",
        "\n",
        "        print(f\"\\nüìä Your Video Analysis:\")\n",
        "        print(f\"   Frames processed: {stats['frames_processed']}\")\n",
        "        print(f\"   Total detections: {stats['total_detections']}\")\n",
        "        print(f\"   Average objects per frame: {np.mean(objects_per_frame):.1f}\")\n",
        "        print(f\"   Peak objects in one frame: {max(objects_per_frame)}\")\n",
        "        print(f\"   Minimum objects detected: {min(objects_per_frame)}\")\n",
        "\n",
        "        # Show key frames from your video\n",
        "        if len(processed_frames) >= 4:\n",
        "            # Find interesting frames\n",
        "            max_detections_frame = np.argmax(objects_per_frame)\n",
        "            min_detections_frame = np.argmin(objects_per_frame)\n",
        "            mid_frame = len(processed_frames) // 2\n",
        "\n",
        "            key_frames = [\n",
        "                processed_frames[0],\n",
        "                processed_frames[mid_frame],\n",
        "                processed_frames[max_detections_frame],\n",
        "                processed_frames[-1]\n",
        "            ]\n",
        "\n",
        "            frame_titles = [\n",
        "                \"First Frame\",\n",
        "                \"Middle Frame\",\n",
        "                f\"Peak Activity ({max(objects_per_frame)} objects)\",\n",
        "                \"Final Frame\"\n",
        "            ]\n",
        "\n",
        "            print(f\"\\nüñºÔ∏è Key Frames from Your Video:\")\n",
        "            show_images_grid(key_frames, frame_titles, rows=2, cols=2, figsize=(16, 12))\n",
        "\n",
        "        # Download your processed video\n",
        "        if os.path.exists(output_path):\n",
        "            print(f\"\\nüíæ Your processed video is ready!\")\n",
        "            try:\n",
        "                files.download(output_path)\n",
        "                print(\"üì• Download started - check your Downloads folder\")\n",
        "            except:\n",
        "                print(f\"File saved as: {output_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Video processing failed\")\n",
        "else:\n",
        "    print(\"‚ùå No video uploaded\")"
      ],
      "metadata": {
        "id": "uerk_3FTk2XR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}